# ============================================
# AI Provider Configuration - COPY TO backend/.env
# ============================================

# Choose your AI provider: 'openai' or 'llama'
AI_PROVIDER=llama

# === Option 1: Llama (Local / Free) ===
# Install Ollama: https://ollama.ai
# Run: ollama serve
# Download model: ollama pull llama2
LLAMA_API_URL=http://localhost:11434
LLAMA_MODEL=llama2

# Popular Llama models:
# - llama2          (7B - Fast, good quality)
# - mistral         (7B - Best balance, recommended)
# - llama2:13b      (13B - Better quality, needs 8GB+ RAM)
# - llama2:70b      (70B - Best quality, needs GPU)

# === Option 2: OpenAI (Cloud / Paid) ===
# Get API key: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-your-key-here

# ============================================
# General Configuration
# ============================================
PORT=5000
NODE_ENV=production
CORS_ORIGIN=https://your-app.vercel.app

# ============================================
# PhantomBuster Configuration
# ============================================
PHANTOMBUSTER_API_KEY=your_key_here
CONNECTIONS_EXPORT_PHANTOM_ID=your_id_here
SEARCH_EXPORT_PHANTOM_ID=your_id_here
MESSAGE_SENDER_PHANTOM_ID=your_id_here
LINKEDIN_SESSION_COOKIE=li_at=...

# ============================================
# Database Configuration
# ============================================
# DATABASE_URL is automatically set by Render
# For local dev:
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=your_password
DB_NAME=linkedin_leads
